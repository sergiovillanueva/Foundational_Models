# Curso: Modelos Fundacionales y Detecci√≥n de Objetos en Visi√≥n Artificial

## Objetivos

Ofrecer una comprensi√≥n s√≥lida de los **modelos fundacionales aplicados a la visi√≥n artificial**, combinando teor√≠a y pr√°ctica intensiva.  
Los estudiantes aprender√°n a utilizar modelos de √∫ltima generaci√≥n disponibles en **Hugging Face Transformers** para tareas como detecci√≥n de objetos, segmentaci√≥n, clasificaci√≥n multimodal, estimaci√≥n de pose, superresoluci√≥n y OCR.  

Tambi√©n se abordar√°n temas relacionados con **licencias, gesti√≥n de entornos (Colab y local)** y buenas pr√°cticas en el uso de modelos preentrenados.

---

## üìÖ Viernes (4 horas)

### 1. Detecci√≥n de Objetos (1h 30 min)

Se introduce la detecci√≥n de objetos como punto de partida, mostrando c√≥mo las arquitecturas modernas sientan las bases de los modelos fundacionales de visi√≥n, extendiendo estos conceptos hacia tareas m√°s generales y multimodales.

- Introducci√≥n a la detecci√≥n de objetos.  
- Comparaci√≥n entre arquitecturas cl√°sicas y modernas.  
- **YOLO:** concepto, versiones y ventajas.  
- **RF-DETR:** arquitectura basada en Transformers.  
- Repaso del entorno / uso en Colab.  
- üìì *Notebook pr√°ctico:* detecci√≥n en im√°genes industriales con modelos preentrenados (YOLO y RF-DETR).  
- Limitaciones y evoluci√≥n hacia arquitecturas fundacionales.

---

### 2. Uso pr√°ctico de Hugging Face y gesti√≥n de entornos (30 min)

Este bloque explica c√≥mo buscar, descargar y ejecutar modelos en **Hugging Face**, gestionando versiones y dependencias tanto en Google Colab como en local.

- Qu√© es Hugging Face (Model Hub, Datasets, Spaces).  
- C√≥mo usar `from_pretrained`.  
- Concepto de *token* y cach√© local.  
- Licencias comunes en IA (Apache 2.0, MIT, GPL...).  
- üìì *Notebook pr√°ctico:* descargar un modelo, inspeccionar sus archivos y probar inferencia b√°sica.

üïí Descanso (15 min)

---

### 3. Modelos Fundacionales Multimodales (1h 45 min)

Explicaci√≥n de la evoluci√≥n conceptual desde los modelos unimodales (texto o imagen) hacia los **modelos multimodales**, culminando en los **Vision-Language Models (VLMs)** capaces de razonar sobre texto e imagen.

- Qu√© son los modelos fundacionales y su importancia.  
- De NLP a visi√≥n: CLIP, SAM, DINO.  
- **CLIP:** relaci√≥n texto-imagen.  
- **BLIP:** captioning y preguntas visuales.  
- **Grounding DINO:** detecci√≥n guiada por texto.  
- **Qwen2.5-VL (VLM):** razonamiento visual y textual avanzado.  
- Comparaci√≥n entre CLIP / BLIP y un VLM moderno.  
- üìì *Notebook pr√°ctico:* clasificaci√≥n, captioning y detecci√≥n con prompts (CLIP, BLIP, Grounding DINO, Qwen2.5-VL).

---

## üìÖ S√°bado (4 horas)

*(El bloque de DINO/DINOv3 se presenta antes de la segmentaci√≥n, por su relaci√≥n conceptual como base de SAM.)*

### 1. Repaso del viernes (30 min)

- Detecci√≥n con YOLO y RF-DETR.  
- CLIP, BLIP, Grounding DINO y Qwen2.5-VL.  
- Preguntas r√°pidas y repaso pr√°ctico.

---detecci√≥n ‚Üí multimodalidad ‚Üí auto-supervisi√≥n ‚Üí segmentaci√≥n ‚Üí pose ‚Üí extras

### 2. DINO / DINOv3 (1h)

- DINO/DINOv3 como extractores de caracter√≠sticas visuales.  
- Aprendizaje auto-supervisado y similitud de parches.  
- Relaci√≥n con **Depth Anything V2** y embeddings multimodales.  
- Visualizaci√≥n de features y proyecciones t-SNE.  
- üìì *Notebook pr√°ctico:* embeddings + t-SNE / similitud de regiones.

---

### 3. Segmentaci√≥n con SAM y variantes (1h)

- **Segment Anything (SAM2):** segmentaci√≥n universal y promptable.  
- Segmentaci√≥n guiada con **Grounding DINO** y **VLMs**.  
- Casos industriales: segmentar componentes o zonas espec√≠ficas.  
- üìì *Notebook pr√°ctico:* segmentaci√≥n interactiva y segmentaci√≥n por texto.

üïí Descanso (15 min)

---

### 4. Estimaci√≥n de Pose (45 min)

- Qu√© es y para qu√© sirve.  
- Modelos sencillos para keypoints humanos en Hugging Face.  
- üìì *Notebook pr√°ctico:* detecci√≥n de pose humana sobre fotos o video.

---

### 5. Otras tareas de visi√≥n fundacional (1h)

- **OCR:** reconocimiento de texto con EasyOCR (ligero y f√°cil de usar).  
- **Superresoluci√≥n:** mejora de calidad visual con Swin2SR.  
- **Background Removal:** eliminaci√≥n de fondo con RMBG.  
- **Matching:** correspondencia de puntos con LightGlue + SuperPoint.  
- üìì *Notebook pr√°ctico:* pruebas r√°pidas con cada t√©cnica.

---

## üß© Modelos utilizados

| Categor√≠a                          | Tarea principal             | Modelo / M√©todo         | ID en Hugging Face                          |
| ---------------------------------- | --------------------------- | ----------------------- | ------------------------------------------- |
| Detecci√≥n de objetos               | Detecci√≥n cl√°sica           | YOLOv8                 | `ultralytics/YOLOv8`                        |
| Detecci√≥n de objetos (Transformer) | Detecci√≥n moderna           | RF-DETR                | `roboflow/rf_detr`                          |
| Multimodal                         | Clasificaci√≥n / Captioning  | CLIP                   | `openai/clip-vit-large-patch14`             |
| Multimodal                         | Captioning / VQA            | BLIP                   | `Salesforce/blip-image-captioning-base`     |
| Detecci√≥n guiada por texto         | Detecci√≥n / Segmentaci√≥n    | Grounding DINO         | `IDEA-Research/grounding-dino-base`         |
| Vision-Language Model (VLM)        | Razonamiento multimodal     | Qwen2.5-VL             | `Qwen/Qwen2.5-VL-3B-Instruct`               |
| Auto-supervisado                   | Extracci√≥n de features      | DINOv3                 | `facebook/dinov3-vitb16-pretrain-lvd1689m`  |
| Segmentaci√≥n                       | Segmentaci√≥n universal      | SAM2                   | `facebook/sam2-hiera-base-plus`             |
| Profundidad                        | Estimaci√≥n de profundidad   | Depth Anything V2      | `depth-anything/Depth-Anything-V2-Small-hf` |
| Pose humana                        | Keypoints humanos           | MoveNet                | `google/movenet-singlepose-lightning`       |
| OCR                                | Reconocimiento de texto     | EasyOCR                | `JaidedAI/EasyOCR`                          |
| Matching                           | Correspondencia de puntos   | LightGlue + SuperPoint | `ETH-CVG/lightglue_superpoint`              |
| Superresoluci√≥n                    | Mejora de calidad visual    | Swin2SR                | `caidas/swin2SR-classical-sr-x4-64`         |
| Eliminaci√≥n de fondo               | Segmentaci√≥n de fondo       | RMBG-1.4               | `briaai/RMBG-1.4`                           |
